import { InferenceSession, Tensor } from "onnxruntime-web";
import React, { useContext, useEffect, useState, useRef } from "react";
import "./assets/scss/App.scss";
import { handleImageScale } from "./components/helpers/scaleHelper";
import { modelScaleProps,modelInputProps } from "./components/helpers/Interfaces";
import { onnxMaskToImage } from "./components/helpers/maskUtils";
import { modelData } from "./components/helpers/onnxModelAPI";
import Stage from "./components/Stage";
import AppContext from "./components/hooks/createContext";
const ort = require("onnxruntime-web");
/* @ts-ignore */
import npyjs from "npyjs";
import "./App.css"

import EnhancedLLM_QA from "./components/authentication/EnhancedLLM_QA";
import Storyline from "./components/authentication/Storyline";
import StageMenu from "./components/authentication/StageMenu"
import EnhancedNestedList from "./components/authentication/EnhancedNestedList"
import Legend from "./components/authentication/Legend"
import Title from "./components/authentication/Title"
import SegmentsAndSeals from "./components/authentication/SegmentsAndSeals"
import QuestionAnsweringComponent from "./components/authentication/QuestionAnswering"
import FullAnswerPanel from "./components/authentication/FullAnswerPanel"
import { stageFocusManager } from './components/Stage';
import StorylineDataManager from "./components/authentication/StorylineDataManager";
// Define image, embedding and model paths
const IMAGE_PATH = `${process.env.PUBLIC_URL}/assets/data/D011518.jpg`;
const IMAGE_EMBEDDING = `${process.env.PUBLIC_URL}/assets/data/D011518.npy`;
const MODEL_DIR = `${process.env.PUBLIC_URL}/model/sam_onnx_example.onnx`;

const App = () => {
  const {
    clicks: [clicks, setClicks],          // âœ… å–å‡º setClicks
    image: [, setImage],
    maskImg: [, setMaskImg],             // âœ… å–å‡º setMaskImg
  } = useContext(AppContext)!;
  const [model, setModel] = useState<InferenceSession | null>(null); // ONNX model
  const [tensor, setTensor] = useState<Tensor | null>(null); // Image embedding tensor

  const [showStage, setShowStage] = useState(false);  // æ§åˆ¶ StageMenu æ˜¾ç¤ºä¸å¦
  const handleShowStage = () => {
    setShowStage(true); // è°ƒæ•´ç¼©æ”¾å€¼
  };

  // === æ–°å¢ï¼šå½“å‰ç‚¹çš„æ ‡ç­¾ï¼ˆ1=æ­£ï¼Œ0=è´Ÿï¼‰ ===
  const [currentLabel, setCurrentLabel] = useState<0 | 1>(1);
  // âœ… æ‚¬åœé¢„è§ˆç‚¹ï¼ˆä¸è¿›æŒä¹… clicksï¼‰
  const [hoverClick, setHoverClick] = useState<modelInputProps | null>(null);

  const [zoomLevel, setZoomLevel] = useState(0.8);

  const [panX, setPanX] = useState(0);
  const [panY, setPanY] = useState(0);
  
  // å›¾æ•°æ®çŠ¶æ€
  const [graphData, setGraphData] = useState<{ nodes: any[], links: any[] } | null>(null);
  const [graphLoading, setGraphLoading] = useState(true); // æ·»åŠ åŠ è½½çŠ¶æ€
  const [isFullGraphMode, setIsFullGraphMode] = useState(false); // æ€»å›¾æ¨¡å¼çŠ¶æ€
  
  // åˆ‡ç‰‡å’Œå°ç« æ˜¾ç¤ºçŠ¶æ€
  const [showSegmentsAndSeals, setShowSegmentsAndSeals] = useState(false);
  const [currentImageId, setCurrentImageId] = useState<string | null>(null); // å½“å‰é€‰ä¸­çš„å›¾ç‰‡IDï¼Œåˆå§‹ä¸ºnull
  
  // æ–°å¢ï¼šé€‰ä¸­é¡¹å’Œç›¸ä¼¼åº¦é˜ˆå€¼çŠ¶æ€
  const [selectedItems, setSelectedItems] = useState<any[]>([]); // é€‰ä¸­çš„åˆ‡ç‰‡/å°ç« 
  const [segmentSimilarityThreshold, setSegmentSimilarityThreshold] = useState<[number, number]>([0.8, 1.0]); // åˆ‡ç‰‡ç›¸ä¼¼åº¦é˜ˆå€¼
  
  // æ–°å¢ï¼šå®Œæ•´ç­”æ¡ˆæ˜¾ç¤ºçŠ¶æ€
  const [fullAnswerData, setFullAnswerData] = useState<any>(null); // å­˜å‚¨è¦æ˜¾ç¤ºçš„å®Œæ•´ç­”æ¡ˆæ•°æ®
  
  // åˆ›å»º ref æ¥å¼•ç”¨ SegmentsAndSeals ç»„ä»¶
  const segmentsAndSealsRef = useRef<any>(null);
  
  // === æ¸…ç©ºæ‰€æœ‰ç‚¹ä¸æ©ç  ===
  const handleReset = () => {
    setClicks([]);        // æ¸…ç©ºç‚¹
    setHoverClick(null);
    setMaskImg(null);     // æ¸…ç©ºå½“å‰ mask
    setPanX(0);           // é‡ç½®æ¨ªå‘å¹³ç§»
    setPanY(0);           // é‡ç½®çºµå‘å¹³ç§»
    // é‡ç½®åè®© Stage ç»„ä»¶é‡æ–°è·å¾—ç„¦ç‚¹
    setTimeout(() => {
      if (stageFocusManager.focusCallback) {
        stageFocusManager.focusCallback();
      }
    }, 0);
  };
  // The ONNX model expects the input to be rescaled to 1024. 
  // The modelScale state variable keeps track of the scale values.
  const [modelScale, setModelScale] = useState<modelScaleProps | null>(null);

  // Initialize the ONNX model. load the image, and load the SAM
  // pre-computed image embedding
  useEffect(() => {
    // Initialize the ONNX model
    const initModel = async () => {
      try {
        if (MODEL_DIR === undefined) return;
        const URL: string = MODEL_DIR;
        const model = await InferenceSession.create(URL);
        setModel(model);
      } catch (e) {
        console.log(e);
      }
    };
    initModel();

    // ä¸å†è‡ªåŠ¨åŠ è½½é»˜è®¤å›¾ç‰‡ï¼Œç­‰å¾…ç”¨æˆ·é€‰æ‹©
    // const url = new URL(IMAGE_PATH, location.origin);
    // loadImage(url);

    // ä¸å†è‡ªåŠ¨åŠ è½½é»˜è®¤çš„ embedding
    // Promise.resolve(loadNpyTensor(IMAGE_EMBEDDING, "float32")).then(
    //   (embedding) => setTensor(embedding)
    // );
    
    // åˆå§‹åŒ–å›¾æ•°æ® - ä½¿ç”¨ StorylineDataManager
    const initGraph = async () => {
      try {
        setGraphLoading(true);
        
        // åˆå§‹çŠ¶æ€ï¼šåªæœ‰çŸ³æ¶›èŠ‚ç‚¹ï¼Œä¸æ·»åŠ ä»»ä½•ç”»ä½œ
        // StorylineDataManager åœ¨åˆå§‹åŒ–æ—¶å·²ç»è‡ªåŠ¨æ·»åŠ äº†çŸ³æ¶›èŠ‚ç‚¹
        
        // è·å–åˆå§‹å›¾æ•°æ®ï¼ˆåªæœ‰çŸ³æ¶›ï¼‰
        const initialGraph = (StorylineDataManager as any).toStorylineFormat();
        setGraphData(initialGraph as any);
        
        console.log('âœ… å›¾æ•°æ®åˆå§‹åŒ–å®Œæˆ (ä»…çŸ³æ¶›èŠ‚ç‚¹), èŠ‚ç‚¹æ•°:', initialGraph.nodes.length);
      } catch (error) {
        console.error('âŒ å›¾æ•°æ®åˆå§‹åŒ–å¤±è´¥:', error);
      } finally {
        setGraphLoading(false);
      }
    };
    initGraph();
  }, []);

  const loadImage = async (url: URL) => {
    try {
      const img = new Image();
      img.src = url.href;
      img.onload = () => {
        const { height, width, samScale } = handleImageScale(img);
        setModelScale({
          height: height,  // original image height
          width: width,  // original image width
          samScale: samScale, // scaling factor for image which has been resized to longest side 1024
        });
        img.width = width;
        img.height = height;
        setImage(img);
      };
    } catch (error) {
      console.log(error);
    }
  };

  // Decode a Numpy file into a tensor. 
  const loadNpyTensor = async (tensorFile: string, dType: string) => {
    let npLoader = new npyjs();
    const npArray = await npLoader.load(tensorFile);
    const tensor = new ort.Tensor(dType, npArray.data, npArray.shape);
    return tensor;
  };

  // Run the ONNX model every time clicks has changed
  useEffect(() => {
    runONNX();
  }, [clicks, hoverClick]);

  const runONNX = async () => {
    try {
      if (model === null || tensor === null || modelScale === null) return;
      // âœ… åˆå¹¶æŒä¹…ç‚¹ + æ‚¬åœç‚¹ï¼ˆä»…é¢„è§ˆä¸å…¥åº“ï¼‰
      const mergedClicks = [...(clicks ?? [])];
      if (hoverClick) mergedClicks.push(hoverClick);
      if (mergedClicks.length === 0) {
        setMaskImg(null);
        return;
      }
      const feeds = modelData({ clicks: mergedClicks, tensor, modelScale });
      if (!feeds) return;
      const results = await model.run(feeds);
      const output = results[model.outputNames[0]];
      setMaskImg(onnxMaskToImage(output.data, output.dims[2], output.dims[3]));
    } catch (e) {
      console.log(e);
    }
  };

  // å¤„ç†å›¾æ›´æ–°çš„å›è°ƒ - ä» QuestionAnswering æ¥æ”¶æ–°å¢çš„èŠ‚ç‚¹å’Œè¾¹
  const handleGraphUpdate = (result: { addedNodes?: any[], addedEdges?: any[], data?: any }) => {
    console.log('ğŸ“Š æ”¶åˆ°å›¾æ•°æ®æ›´æ–°:', result);
    
    // è·å–æœ€æ–°çš„å›¾æ•°æ®
    const updatedGraph = (StorylineDataManager as any).toStorylineFormat();
    
    // å¼ºåˆ¶åˆ›å»ºæ–°å¯¹è±¡å¼•ç”¨ä»¥è§¦å‘Reacté‡æ–°æ¸²æŸ“
    setGraphData({
      nodes: [...updatedGraph.nodes],
      links: [...updatedGraph.links]
    });
    
    console.log('âœ… å›¾æ•°æ®å·²æ›´æ–°, èŠ‚ç‚¹æ•°:', updatedGraph.nodes.length, 'è¾¹æ•°:', updatedGraph.links.length);
  };

  // å¤„ç†æ¸…ç©ºé€‰æ‹©çš„å›è°ƒ - æŸ¥è¯¢æˆåŠŸåæ¸…ç©ºåˆ‡ç‰‡å’Œå°ç« é€‰æ‹©
  const handleClearSelection = () => {
    console.log('ğŸ§¹ Appæ”¶åˆ°æ¸…ç©ºé€‰æ‹©è¯·æ±‚');
    if (segmentsAndSealsRef.current) {
      segmentsAndSealsRef.current.clearSelection();
    }
  };

  // å¤„ç†æ˜¾ç¤ºå®Œæ•´ç­”æ¡ˆçš„å›è°ƒ
  const handleShowFullAnswer = (historyItem: any) => {
    console.log('ğŸ“– æ˜¾ç¤ºå®Œæ•´ç­”æ¡ˆ:', historyItem);
    setFullAnswerData(historyItem);
  };

  // å¤„ç†å›¾ç‰‡é€‰æ‹©
  const handleImageSelect = (selectedImage: any) => {
    console.log('ğŸ–¼ï¸ ç”¨æˆ·é€‰æ‹©äº†å›¾ç‰‡:', selectedImage);
    
    // ä¿å­˜å½“å‰å›¾ç‰‡ID
    setCurrentImageId(selectedImage.id);
    
    // æ¸…ç©ºé€‰ä¸­é¡¹
    setSelectedItems([]);
    
    // ğŸ”¥ æ¸…ç©ºä¹‹å‰çš„æ‰€æœ‰å›¾è°±æ•°æ®ï¼Œåªä¿ç•™çŸ³æ¶›èŠ‚ç‚¹
    console.log('ğŸ—‘ï¸ æ¸…ç©ºä¹‹å‰çš„å›¾è°±ï¼Œé‡ç½®ä¸ºåªæœ‰çŸ³æ¶›èŠ‚ç‚¹');
    (StorylineDataManager as any).reset();
    
    // æ·»åŠ æ–°é€‰æ‹©çš„ç”»ä½œèŠ‚ç‚¹åˆ°å›¾è°±
    (StorylineDataManager as any).addPaintingNode(selectedImage.id, selectedImage.name || `ç”»ä½œ ${selectedImage.id}`);
    
    // æ›´æ–°å›¾æ•°æ®
    const updatedGraph = (StorylineDataManager as any).toStorylineFormat();
    setGraphData({
      nodes: [...updatedGraph.nodes],
      links: [...updatedGraph.links]
    });
    
    console.log('âœ… å›¾è°±å·²æ›´æ–°: çŸ³æ¶› + ' + selectedImage.id + ', èŠ‚ç‚¹æ•°:', updatedGraph.nodes.length);
    
    // ä½¿ç”¨å›¾ç‰‡é€‰æ‹©å™¨æä¾›çš„å®Œæ•´è·¯å¾„ï¼ˆå·²åŒ…å« PUBLIC_URLï¼‰
    const imagePath = selectedImage.path;
    const url = new URL(imagePath, location.origin);
    
    // åŠ è½½æ–°å›¾ç‰‡
    loadImage(url);
    
    // åŠ è½½å¯¹åº”çš„ NPY æ–‡ä»¶ (Paintings_npy ä¸­çš„åŒåæ–‡ä»¶)
    const npyPath = `${process.env.PUBLIC_URL}/assets/data/Paintings_npy/${selectedImage.id}.npy`;
    console.log('ğŸ“¦ æ­£åœ¨åŠ è½½ NPY æ–‡ä»¶:', npyPath);
    
    Promise.resolve(loadNpyTensor(npyPath, "float32")).then(
      (embedding) => {
        setTensor(embedding);
        console.log('âœ… NPY æ–‡ä»¶åŠ è½½æˆåŠŸ:', npyPath);
      }
    ).catch((error) => {
      console.error('âŒ NPY æ–‡ä»¶åŠ è½½å¤±è´¥:', error);
      console.log('âš ï¸ å°è¯•çš„è·¯å¾„:', npyPath);
    });
    
    // é‡ç½®çŠ¶æ€
    handleReset();
  };

  // å¤„ç†æ˜¾ç¤ºåˆ‡ç‰‡å’Œå°ç« 
  const handleShowSegments = () => {
    // åªæœ‰é€‰æ‹©äº†å›¾ç‰‡åæ‰å…è®¸æ˜¾ç¤ºåˆ‡ç‰‡å’Œå°ç« 
    if (!currentImageId) {
      console.warn('âš ï¸ è¯·å…ˆé€‰æ‹©ä¸€å¼ å›¾ç‰‡');
      return;
    }
    setShowSegmentsAndSeals(prev => !prev);
  };

  // å¤„ç†é€‰ä¸­é¡¹å˜åŒ–
  const handleSelectionChange = (newSelectedItems: any[]) => {
    console.log('ï¿½ é€‰ä¸­é¡¹å˜åŒ–:', newSelectedItems);
    setSelectedItems(newSelectedItems);
  };

  // å¤„ç†ç›¸ä¼¼åº¦é˜ˆå€¼å˜åŒ–
  const handleSegmentSimilarityChange = (newThreshold: [number, number]) => {
    console.log('ğŸ“Š ç›¸ä¼¼åº¦é˜ˆå€¼å˜åŒ–:', newThreshold);
    setSegmentSimilarityThreshold(newThreshold);
  };

  return <>
    <div className="top-bar">
      <Title />
    </div>
    <div className="bottom-container">
      <div className="left-side">
        <div className="left-side-border">
          {/* âœ… ä¼ é€’ currentLabel ä¸ onReset */}
          <StageMenu
            showStage={handleShowStage}
            currentLabel={currentLabel}
            onChangeLabel={setCurrentLabel}
            onReset={handleReset}
            onImageSelect={handleImageSelect}
            onShowSegments={handleShowSegments}
          />
          {/* âœ… æŠŠ currentLabel ä¼ ç»™ Stageï¼›zoom ä»å¤–æ§ï¼Œæ»šè½®é€šè¿‡ onZoomChange æ›´æ–° */}
          {showStage && (
            <Stage
              zoomLevel={zoomLevel}
              onZoomChange={setZoomLevel}
              currentLabel={currentLabel}
              onHoverChange={setHoverClick}   // âœ… æ–°å¢ï¼šæ‚¬åœæ—¶è®¾ç½®é¢„è§ˆç‚¹
              onHoverEnd={() => setHoverClick(null)} // âœ… ç¦»å¼€æ—¶æ¸…ç©ºé¢„è§ˆ
              panX={panX}
              panY={panY}
              onPanXChange={setPanX}
              onPanYChange={setPanY}
            />
          )}
        </div>
      </div>
      <div className="right-side">
        <div className="right-side-top">
          <div className="right-side-top-left">
            <EnhancedNestedList 
              onGraphUpdate={handleGraphUpdate} 
              onShowFullAnswer={handleShowFullAnswer}
            />
            
            {/* åªæœ‰æ•°æ®åŠ è½½å®Œæˆä¸”æœ‰æ•ˆæ—¶æ‰æ¸²æŸ“Storylineï¼Œé¿å…é—ªçƒ */}
            {!graphLoading && graphData && graphData.nodes.length > 0 ? (
              <Storyline 
                nodesData={graphData.nodes as any}
                linksData={graphData.links as any}
              />
            ) : (
              <div className="storyline" style={{ 
                display: 'flex', 
                alignItems: 'center', 
                justifyContent: 'center',
                color: '#999',
                fontSize: '14px'
              }}>
                {graphLoading ? 'åŠ è½½å›¾æ•°æ®ä¸­...' : 'æš‚æ— æ•°æ®'}
              </div>
            )}
            <Legend onSegmentSimilarityChange={handleSegmentSimilarityChange} />
          </div>
        </div>
        {/* åˆ‡ç‰‡å’Œå°ç« è§†å›¾ / é—®ç­”ç•Œé¢ */}
        <div className="right-side-buttom">
          <div style={{ 
            display: 'flex', 
            flexDirection: 'column', 
            height: '100%', 
            width: '100%',
            boxSizing: 'border-box',
            overflow: 'hidden'
          }}>
            {/* ä¸Šæ–¹: åˆ‡ç‰‡å’Œå°ç« é€‰æ‹© - è‡ªé€‚åº”é«˜åº¦ */}
            <div style={{ 
              flex: '1',
              minHeight: 0,
              overflow: 'auto',
              marginBottom: '8px',
              backgroundColor: '#f5f5f5'
            }}>
              {showSegmentsAndSeals && 
                React.createElement(SegmentsAndSeals as any, {
                  ref: segmentsAndSealsRef,
                  selectedImageId: currentImageId,
                  onSelectionChange: handleSelectionChange
                })
              }
            </div>
            {/* ä¸‹æ–¹: é—®ç­”ç•Œé¢ - å›ºå®šè¾“å…¥æ¡†é«˜åº¦ï¼Œå æ®å‰©ä½™ç©ºé—´ */}
            <div style={{ 
              flex: '0 0 auto',
              height: '57px', // è¾“å…¥æ¡†å®¹å™¨é«˜åº¦ (45pxè¾“å…¥æ¡† + 12px padding)
              minHeight: '57px',
              overflow: 'hidden'
            }}>
              {React.createElement(QuestionAnsweringComponent as any, {
                selectedImageId: currentImageId,
                selectedItems: selectedItems,
                segmentSimilarityThreshold: segmentSimilarityThreshold,
                onGraphUpdate: handleGraphUpdate,
                onClearSelection: handleClearSelection
              })}
            </div>
          </div>
        </div>
      </div>
    </div>

    {/* å®Œæ•´ç­”æ¡ˆæ˜¾ç¤ºé¢æ¿ */}
    {fullAnswerData && (
      <FullAnswerPanel 
        answerData={fullAnswerData}
        onClose={() => setFullAnswerData(null)}
      />
    )}

  </>
};

export default App;
